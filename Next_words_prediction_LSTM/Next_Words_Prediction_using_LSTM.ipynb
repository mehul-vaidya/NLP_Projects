{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubiBNesKA9T8"
      },
      "source": [
        "# LSTM Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyks1KwtA9T_"
      },
      "source": [
        "# **Text Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BADYwQhXA9UA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "opu9YSIwA9UE"
      },
      "outputs": [],
      "source": [
        "with open('alice_in_wonderland.txt', 'r', encoding='utf-8') as infile:\n",
        "    data = infile.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcF8hC0QA9UG"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "beTozUDDA9UH"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "    # Remove special characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "p-TF_gjnA9UI"
      },
      "outputs": [],
      "source": [
        "# Preprocessing pipeline\n",
        "def preprocess_pipeline(data) -> 'list':\n",
        "    # Split by newline character\n",
        "    sentences = data.split('\\n')\n",
        "    for i in range(len(sentences)):\n",
        "        sentences[i] = preprocess(sentences[i])\n",
        "    # Remove leading and trailing spaces\n",
        "    sentences = [s.strip() for s in sentences]\n",
        "    # Drop empty sentences\n",
        "    sentences = [s for s in sentences if len(s) > 0]\n",
        "    # Tokenization\n",
        "    tokenized = []\n",
        "    for sentence in sentences:\n",
        "        # Convert to lowercase\n",
        "        sentence = sentence.lower()\n",
        "        tokenized.append(sentence)\n",
        "    return tokenized\n",
        "\n",
        "# Tokenize sentences\n",
        "tokenized_sentences = preprocess_pipeline(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsy0vlFuNsrX",
        "outputId": "1bc6b4c8-29b4-4fce-c946-41fd0f0570e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['title alices adventures in wonderland',\n",
              " 'author lewis carroll',\n",
              " 'chapter i',\n",
              " 'down the rabbithole',\n",
              " 'alice was beginning to get very tired of sitting by her sister',\n",
              " 'on the bank and of having nothing to do once or twice she had',\n",
              " 'peeped into the book her sister was reading but it had no',\n",
              " 'pictures or conversations in it and what is the use of a book',\n",
              " 'thought alice without pictures or conversation',\n",
              " 'so she was considering in her own mind as well as she could']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tokenized_sentences[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nnrxGu-BA9UJ"
      },
      "outputs": [],
      "source": [
        "# Tokenize words\n",
        "tokenizer = Tokenizer(oov_token='<oov>')\n",
        "tokenizer.fit_on_texts(tokenized_sentences)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "#we create n-grams\n",
        "'''\n",
        "sentence\n",
        "i     am     very     proud\n",
        "will look like\n",
        "0     0      0        i\n",
        "0     0      i        am\n",
        "0     i      am       very\n",
        "i     am     very     proud\n",
        "'''\n",
        "input_sequences = []\n",
        "for line in tokenized_sentences:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i + 1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "#Pad sequences\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len"
      ],
      "metadata": {
        "id": "rzoHnA8uC5dw",
        "outputId": "3728572c-9078-4c75-c9ad-cba99f578877",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNaEYfq8PuRN",
        "outputId": "a577e8ef-3aa2-4f47-ae2f-3a7bb0bd74d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0, 1474,  300],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0, 1474,  300,  528],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0, 1474,  300,  528,   12],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "        1474,  300,  528,   12,  829],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0, 1475, 1476],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0, 1475, 1476, 1477],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,  301,   10],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,   37,    2],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,   37,    2,  830],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,   11,   14]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "input_sequences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMh3ovgBQ6fV",
        "outputId": "2ef0a68c-b435-436d-e926-f57ffec7f799"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23710, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "input_sequences.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "p327lo4yA9UJ"
      },
      "outputs": [],
      "source": [
        "# Creates labels with input sequences\n",
        "'''\n",
        "0     0      0        i\n",
        "0     0      i        am\n",
        "0     i      am       very\n",
        "i     am     very     proud\n",
        "\n",
        "X {column 0 to 2}\n",
        "0     0      0\n",
        "0     0      i\n",
        "0     i      am\n",
        "i     am     very\n",
        "\n",
        "Y {last column}\n",
        "i\n",
        "am\n",
        "very\n",
        "proud\n",
        "'''\n",
        "X,labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KSuxB1WnA9UK"
      },
      "outputs": [],
      "source": [
        "# Split data into training, validation, and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_temp, X_val_test, y_train_temp, y_val_test = train_test_split(X, ys, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLYKiINFA9UK"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsI97b2JA9UK",
        "outputId": "1f608a4a-a271-47e9-d6f5-8991c283f911"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "593/593 [==============================] - 34s 47ms/step - loss: 5.9401 - accuracy: 0.0833 - val_loss: 5.5710 - val_accuracy: 0.1088\n",
            "Epoch 2/50\n",
            "593/593 [==============================] - 10s 17ms/step - loss: 5.0445 - accuracy: 0.1337 - val_loss: 5.4777 - val_accuracy: 0.1303\n",
            "Epoch 3/50\n",
            "593/593 [==============================] - 9s 16ms/step - loss: 4.4088 - accuracy: 0.1728 - val_loss: 5.5924 - val_accuracy: 0.1392\n",
            "Epoch 4/50\n",
            "593/593 [==============================] - 10s 17ms/step - loss: 3.8678 - accuracy: 0.2136 - val_loss: 5.8605 - val_accuracy: 0.1383\n",
            "Epoch 5/50\n",
            "593/593 [==============================] - 9s 16ms/step - loss: 3.3726 - accuracy: 0.2627 - val_loss: 6.1460 - val_accuracy: 0.1257\n",
            "Epoch 6/50\n",
            "593/593 [==============================] - 10s 17ms/step - loss: 2.9704 - accuracy: 0.3226 - val_loss: 6.4325 - val_accuracy: 0.1210\n",
            "Epoch 7/50\n",
            "593/593 [==============================] - 10s 17ms/step - loss: 2.6420 - accuracy: 0.3706 - val_loss: 6.6644 - val_accuracy: 0.1185\n",
            "Epoch 8/50\n",
            "593/593 [==============================] - 8s 13ms/step - loss: 2.3943 - accuracy: 0.4147 - val_loss: 7.0279 - val_accuracy: 0.1109\n",
            "Epoch 9/50\n",
            "593/593 [==============================] - 10s 17ms/step - loss: 2.2126 - accuracy: 0.4483 - val_loss: 7.1464 - val_accuracy: 0.1168\n",
            "Epoch 10/50\n",
            "593/593 [==============================] - 9s 15ms/step - loss: 2.0442 - accuracy: 0.4796 - val_loss: 7.3519 - val_accuracy: 0.1223\n",
            "Epoch 11/50\n",
            "593/593 [==============================] - 9s 16ms/step - loss: 1.8763 - accuracy: 0.5146 - val_loss: 7.6205 - val_accuracy: 0.1059\n",
            "Epoch 12/50\n",
            "593/593 [==============================] - 9s 16ms/step - loss: 1.7728 - accuracy: 0.5364 - val_loss: 7.8534 - val_accuracy: 0.1143\n",
            "Epoch 13/50\n",
            "593/593 [==============================] - 9s 15ms/step - loss: 1.7059 - accuracy: 0.5527 - val_loss: 8.1164 - val_accuracy: 0.1232\n",
            "Epoch 14/50\n",
            "593/593 [==============================] - 9s 15ms/step - loss: 1.6544 - accuracy: 0.5595 - val_loss: 8.2953 - val_accuracy: 0.1067\n",
            "Epoch 15/50\n",
            "593/593 [==============================] - 10s 17ms/step - loss: 1.6367 - accuracy: 0.5692 - val_loss: 8.4482 - val_accuracy: 0.1168\n",
            "Epoch 16/50\n",
            "593/593 [==============================] - 9s 14ms/step - loss: 1.5651 - accuracy: 0.5827 - val_loss: 8.7358 - val_accuracy: 0.1075\n",
            "Epoch 17/50\n",
            "593/593 [==============================] - 9s 16ms/step - loss: 1.4927 - accuracy: 0.5949 - val_loss: 8.8688 - val_accuracy: 0.1160\n",
            "Epoch 18/50\n",
            "593/593 [==============================] - 9s 16ms/step - loss: 1.5040 - accuracy: 0.5916 - val_loss: 9.0458 - val_accuracy: 0.1126\n",
            "Epoch 19/50\n",
            "593/593 [==============================] - 9s 14ms/step - loss: 1.4723 - accuracy: 0.6016 - val_loss: 9.1380 - val_accuracy: 0.1194\n",
            "Epoch 20/50\n",
            "593/593 [==============================] - 10s 17ms/step - loss: 1.4312 - accuracy: 0.6100 - val_loss: 9.2558 - val_accuracy: 0.1185\n",
            "Epoch 21/50\n",
            "593/593 [==============================] - 8s 13ms/step - loss: 1.4371 - accuracy: 0.6028 - val_loss: 9.4535 - val_accuracy: 0.1105\n",
            "Epoch 22/50\n",
            "593/593 [==============================] - 10s 16ms/step - loss: 1.4297 - accuracy: 0.6088 - val_loss: 9.5195 - val_accuracy: 0.1168\n",
            "Epoch 23/50\n",
            "593/593 [==============================] - 9s 16ms/step - loss: 1.4104 - accuracy: 0.6127 - val_loss: 9.6331 - val_accuracy: 0.1135\n",
            "Epoch 24/50\n",
            "593/593 [==============================] - 8s 14ms/step - loss: 1.4002 - accuracy: 0.6179 - val_loss: 9.7662 - val_accuracy: 0.1139\n",
            "Epoch 25/50\n",
            "593/593 [==============================] - 8s 14ms/step - loss: 1.4302 - accuracy: 0.6086 - val_loss: 9.9013 - val_accuracy: 0.1130\n",
            "Epoch 26/50\n",
            "593/593 [==============================] - 7s 12ms/step - loss: 1.3844 - accuracy: 0.6187 - val_loss: 9.9463 - val_accuracy: 0.1054\n",
            "Epoch 27/50\n",
            "593/593 [==============================] - 9s 14ms/step - loss: 1.3968 - accuracy: 0.6165 - val_loss: 10.1077 - val_accuracy: 0.1046\n",
            "Epoch 28/50\n",
            "593/593 [==============================] - 7s 12ms/step - loss: 1.3849 - accuracy: 0.6188 - val_loss: 10.1571 - val_accuracy: 0.1109\n",
            "Epoch 29/50\n",
            "593/593 [==============================] - 10s 16ms/step - loss: 1.3912 - accuracy: 0.6153 - val_loss: 10.2793 - val_accuracy: 0.1173\n",
            "Epoch 30/50\n",
            "593/593 [==============================] - 8s 14ms/step - loss: 1.4068 - accuracy: 0.6151 - val_loss: 10.3711 - val_accuracy: 0.1097\n",
            "Epoch 31/50\n",
            "593/593 [==============================] - 8s 13ms/step - loss: 1.3875 - accuracy: 0.6167 - val_loss: 10.4284 - val_accuracy: 0.1118\n",
            "Epoch 32/50\n",
            "593/593 [==============================] - 10s 17ms/step - loss: 1.4011 - accuracy: 0.6159 - val_loss: 10.4599 - val_accuracy: 0.1151\n",
            "Epoch 33/50\n",
            "593/593 [==============================] - 8s 13ms/step - loss: 1.3877 - accuracy: 0.6152 - val_loss: 10.6424 - val_accuracy: 0.1143\n",
            "Epoch 34/50\n",
            "593/593 [==============================] - 10s 17ms/step - loss: 1.3517 - accuracy: 0.6247 - val_loss: 10.7383 - val_accuracy: 0.1033\n",
            "Epoch 35/50\n",
            "593/593 [==============================] - 11s 18ms/step - loss: 1.3983 - accuracy: 0.6154 - val_loss: 10.8038 - val_accuracy: 0.1033\n",
            "Epoch 36/50\n",
            "593/593 [==============================] - 9s 14ms/step - loss: 1.4138 - accuracy: 0.6122 - val_loss: 10.8043 - val_accuracy: 0.1092\n",
            "Epoch 37/50\n",
            "593/593 [==============================] - 10s 16ms/step - loss: 1.3759 - accuracy: 0.6233 - val_loss: 10.8196 - val_accuracy: 0.1075\n",
            "Epoch 38/50\n",
            "593/593 [==============================] - 9s 16ms/step - loss: 1.3283 - accuracy: 0.6311 - val_loss: 11.0849 - val_accuracy: 0.1071\n",
            "Epoch 39/50\n",
            "593/593 [==============================] - 9s 14ms/step - loss: 1.3153 - accuracy: 0.6367 - val_loss: 11.0949 - val_accuracy: 0.1109\n",
            "Epoch 40/50\n",
            "593/593 [==============================] - 10s 16ms/step - loss: 1.3674 - accuracy: 0.6220 - val_loss: 11.1169 - val_accuracy: 0.1004\n",
            "Epoch 41/50\n",
            "593/593 [==============================] - 8s 14ms/step - loss: 1.3622 - accuracy: 0.6267 - val_loss: 11.3200 - val_accuracy: 0.1021\n",
            "Epoch 42/50\n",
            "593/593 [==============================] - 10s 16ms/step - loss: 1.4013 - accuracy: 0.6171 - val_loss: 11.3281 - val_accuracy: 0.1012\n",
            "Epoch 43/50\n",
            "593/593 [==============================] - 9s 16ms/step - loss: 1.3669 - accuracy: 0.6228 - val_loss: 11.2564 - val_accuracy: 0.1147\n",
            "Epoch 44/50\n",
            "593/593 [==============================] - 8s 14ms/step - loss: 1.3184 - accuracy: 0.6379 - val_loss: 11.2816 - val_accuracy: 0.1029\n",
            "Epoch 45/50\n",
            "593/593 [==============================] - 10s 16ms/step - loss: 1.3088 - accuracy: 0.6368 - val_loss: 11.4568 - val_accuracy: 0.0995\n",
            "Epoch 46/50\n",
            "593/593 [==============================] - 9s 15ms/step - loss: 1.3491 - accuracy: 0.6271 - val_loss: 11.5743 - val_accuracy: 0.1105\n",
            "Epoch 47/50\n",
            "593/593 [==============================] - 9s 15ms/step - loss: 1.3432 - accuracy: 0.6273 - val_loss: 11.5049 - val_accuracy: 0.1092\n",
            "Epoch 48/50\n",
            "593/593 [==============================] - 10s 16ms/step - loss: 1.3536 - accuracy: 0.6270 - val_loss: 11.7340 - val_accuracy: 0.1067\n",
            "Epoch 49/50\n",
            "593/593 [==============================] - 8s 14ms/step - loss: 1.3040 - accuracy: 0.6388 - val_loss: 11.6574 - val_accuracy: 0.1063\n",
            "Epoch 50/50\n",
            "593/593 [==============================] - 9s 16ms/step - loss: 1.3163 - accuracy: 0.6350 - val_loss: 11.7985 - val_accuracy: 0.1016\n"
          ]
        }
      ],
      "source": [
        "# Define your model\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100))\n",
        "model.add(Bidirectional(LSTM(150)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "adam = Adam(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_temp, y_train_temp, epochs=50, validation_data=(X_val, y_val), verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kQ-ASCRA9UL"
      },
      "source": [
        "# Save Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6XJXGG1ik_lH"
      },
      "outputs": [],
      "source": [
        "model.save('Sentence_autocompletion.keras')\n",
        "model = tf.keras.models.load_model('Sentence_autocompletion.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF5Twq4kA9UM"
      },
      "source": [
        "# Make Actual Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rcYeU1utA9UM"
      },
      "outputs": [],
      "source": [
        "def predict_top_five_words(model, tokenizer, seed_text):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    top_five_indexes = np.argsort(predicted[0])[::-1][:5]\n",
        "    top_five_words = []\n",
        "    for index in top_five_indexes:\n",
        "        for word, idx in tokenizer.word_index.items():\n",
        "            if idx == index:\n",
        "                top_five_words.append(word)\n",
        "                break\n",
        "    return top_five_words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX8RcW0eA9UM",
        "outputId": "2f71705e-3639-4f8e-c4d5-7cc5b855831d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dear', 'time', 'own', 'youth', 'said']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "seed_text = \"Alice is my\"\n",
        "output= predict_top_five_words(model ,tokenizer ,seed_text )\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNDDZAZjA9UN",
        "outputId": "8afb2dfd-37ae-419d-e096-bccfa90155a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['do', 'said', 'spoke', 'you', 'thought']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "seed_text = \"Alice I will never\"\n",
        "output= predict_top_five_words(model ,tokenizer ,seed_text )\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uQeClXwPuBKQ",
        "outputId": "501de10e-9c26-4bee-d22b-b7e7de954663"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "sxAb7h_kulgo"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"next_word_Prediction.json\", \"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9wSN5Qhdup_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9237390-b843-40b2-b805-4a6535b5ee17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# saving\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "-sC-n7o5AoTX"
      },
      "execution_count": 15,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4758440,
          "sourceId": 8065627,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4758543,
          "sourceId": 8065761,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4759977,
          "sourceId": 8067728,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30674,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}